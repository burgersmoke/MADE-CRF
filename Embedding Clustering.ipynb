{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal of this notebook is to cluster and assign cluster numbers to each word so that they might be useful as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "c:\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this package can be found here : \n",
    "# https://github.com/Hironsan/anago\n",
    "# after cloning, it can be installed with the typical : \n",
    "# python setup.py install\n",
    "\n",
    "import anago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n",
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "print(sklearn.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "# importing a CRF layer (originally from Keras-contrib)\n",
    "from keras_contrib.layers.crf import CRF\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, LSTM, GRU, Bidirectional, Embedding, Input, Dropout, Lambda\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported custom BASIC modules\n"
     ]
    }
   ],
   "source": [
    "import basic\n",
    "from basic.nlp.tokenizers import clinical_tokenizers\n",
    "from basic.nlp.annotation.annotation import Annotation, AnnotatedDocument\n",
    "from basic.MADE.madetokenizer import build_made_tokenizer\n",
    "from basic.nlp.sequenceutils import get_sentence_bio_tagged_tokens\n",
    "from basic.MADE.madeutils import read_made_data, train_default_anago_model, get_all_sentence_tokens_and_tags, create_model, gather_validation_metrics\n",
    "\n",
    "print('Imported custom BASIC modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_BASE_DIR = r'c:\\temp_embeddings'\n",
    "\n",
    "#PRETRAINED_EMBEDDINGS_FILENAME = r'wikipedia-pubmed-and-PMC-w2v.bin'\n",
    "PRETRAINED_EMBEDDINGS_FILENAME = r'pubmed+wiki+pitts-nopunct-lower-cbow-n10.bin'\n",
    "\n",
    "K_CLUSTERS = 500\n",
    "ENABLED_BATCH_KMEANS = True\n",
    "KMEANS_BATCH_SIZE = 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.KeyedVectors object at 0x0000021CD5874D68>\n"
     ]
    }
   ],
   "source": [
    "# let's load some pretrained embeddings as well\n",
    "\n",
    "# NOTE : These embeddings are made available here:\n",
    "# http://evexdb.org/pmresources/vec-space-models/\n",
    "\n",
    "pretrained_word_vectors = KeyedVectors.load_word2vec_format(os.path.join(EMBEDDINGS_BASE_DIR, PRETRAINED_EMBEDDINGS_FILENAME), binary=True)  # C binary format\n",
    "                                                 \n",
    "print(pretrained_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_word_vectors['the'].shape)\n",
    "\n",
    "pretrained_embeddings_dimensions = pretrained_word_vectors['the'].shape[0]\n",
    "print(pretrained_embeddings_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = pretrained_word_vectors\n",
    "embeddings_dimensions = pretrained_embeddings_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running K means\n",
      "Using batch KMeans\n",
      "K means trained\n",
      "Wall time: 17min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_vectors = pretrained_word_vectors.syn0\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "print('Running K means')\n",
    "\n",
    "if ENABLED_BATCH_KMEANS:\n",
    "    print('Using batch KMeans')\n",
    "    kmeans = MiniBatchKMeans(n_clusters = K_CLUSTERS, \n",
    "                         #n_jobs = -2, \n",
    "                         batch_size = KMEANS_BATCH_SIZE)\n",
    "else:\n",
    "    print('Using original recipe KMeans')\n",
    "    kmeans = KMeans( n_clusters = K_CLUSTERS, n_jobs = -2 )\n",
    "\n",
    "cluster_idx = kmeans.fit_predict( word_vectors )\n",
    "\n",
    "print('K means trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('</s>', 346), ('the', 62), ('of', 323), ('and', 5), ('in', 323), ('to', 406), ('a', 329), ('with', 88), ('was', 461), ('for', 16), ('is', 71), ('were', 15), ('by', 251), ('that', 182), ('as', 71), ('on', 5), ('from', 143), ('at', 75), ('or', 236), ('this', 71), ('are', 71), ('an', 329), ('be', 182), ('patients', 432), ('not', 182), ('which', 329), ('it', 182), ('these', 229), ('we', 86), ('have', 71), ('after', 436), ('p', 216), ('cells', 266), ('has', 71), ('but', 182), ('had', 436), ('also', 477), ('than', 252), ('s', 407), ('two', 199), ('he', 254), ('been', 173), ('between', 252), ('their', 286), ('one', 465), ('his', 20), ('study', 86), ('all', 287), ('may', 229), ('no', 182)]\n"
     ]
    }
   ],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number\n",
    "word_cluster_map = dict(zip(pretrained_word_vectors.wv.index2word, cluster_idx ))\n",
    "\n",
    "print(list(word_cluster_map.items())[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352549\n"
     ]
    }
   ],
   "source": [
    "print(len(word_cluster_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cluster map pickle to : WordClusters_K500_BatchKmeans_pubmed+wiki+pitts-nopunct-lower-cbow-n10.pickle\n",
      "DONE writing cluster map pickle\n"
     ]
    }
   ],
   "source": [
    "typename = 'KMeans'\n",
    "if ENABLED_BATCH_KMEANS:\n",
    "    typename = 'BatchKmeans'\n",
    "\n",
    "map_pickle_file_name = 'WordClusters_K{0}_{1}_{2}.pickle'.format(K_CLUSTERS, typename, PRETRAINED_EMBEDDINGS_FILENAME.split('.')[0])\n",
    "\n",
    "print('Writing cluster map pickle to : {}'.format(map_pickle_file_name))\n",
    "      \n",
    "with open(map_pickle_file_name, 'wb') as handle:\n",
    "    pickle.dump(word_cluster_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "print('DONE writing cluster map pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
